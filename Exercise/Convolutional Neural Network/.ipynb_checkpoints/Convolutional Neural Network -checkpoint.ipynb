{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a convolutional neural network with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This example is using TensorFlow layers API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Overview\n",
    "<img src=\"https://camo.githubusercontent.com/afc8cecd033ab300799ceb2bf3b593efa3bda2b7/687474703a2f2f706572736f6e616c2e69652e6375686b2e6564752e686b2f7e63636c6f792f70726f6a6563745f7461726765745f636f64652f696d616765732f666967332e706e67\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This example is using MNIST handwritten digits.\n",
    "<img src=\"https://camo.githubusercontent.com/b06741b45df8ffe29c7de999ab2ec4ff6b2965ba/687474703a2f2f6e657572616c6e6574776f726b73616e64646565706c6561726e696e672e636f6d2f696d616765732f6d6e6973745f3130305f6469676974732e706e67\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting train parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_steps = 2000\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input = 784 # MNIST data input (img shape:28*28)\n",
    "num_classes = 10 # MNIST total classes (0~9 digits)\n",
    "dropout = 0.25 # Dropout, probability to drop a unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x_dict, n_classes, dropout,reuse, is_training):\n",
    "    # Define a scope for reusing the variables\n",
    "    with tf.variable_scope('ConvNet', reuse=reuse):\n",
    "        # TF Estimator input is a dict, in case of multiple inputs\n",
    "        x = x_dict['images']\n",
    "\n",
    "        # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n",
    "        # Reshape to match picture format [Height x Width x Channel]\n",
    "        # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
    "        x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "        \n",
    "        # Convolution Layer with 32 filers and a kernel size of 5\n",
    "        conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n",
    "        # Max pooling (down-smapling) with strides of 2 and kernel size of 2\n",
    "        conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
    "        \n",
    "        # Convolution Layer with 64 filters and a kernel size of 3\n",
    "        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n",
    "        conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n",
    "        \n",
    "        # Flaten the data to a 1-D vector for the fully connected layer\n",
    "        fc1 = tf.contrib.layers.flatten(conv2)\n",
    "        \n",
    "        # Fully conneted layer (in tf contrib folder for now)\n",
    "        fc1 = tf.layers.dense(fc1, 1024)\n",
    "        # Apply Dropout (if is training is Flase, dropout is not applied)\n",
    "        fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)\n",
    "        \n",
    "        # Output layer, class_prediction\n",
    "        out = tf.layers.dense(fc1, n_classes)\n",
    "        \n",
    "    return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model function (following TF Estimator Template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "   \n",
    "    # Build the neural network\n",
    "    # Because Dropout have different behavior at trianing and predction time, we\n",
    "    # need to creat 2 distinct computation graphs that still share the same weights\n",
    "    logits_train = conv_net(features, num_classes, dropout, reuse=False, is_training=True)\n",
    "    logits_test = conv_net(features, num_classes, dropout, reuse=True, is_training=False)\n",
    "    \n",
    "    # Predictions\n",
    "    pred_classes = tf.argmax(logits_test, axis=1)\n",
    "    pred_probas = tf.nn.softmax(logits_test)\n",
    "    \n",
    "    # If prediction mode, early return\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)\n",
    "    \n",
    "    # Define loss and optimizer\n",
    "    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "              logits=logits_train, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    # Evalute the accuracy of the model\n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "    \n",
    "    # TF Estimators requires to return a EstimaorSpec, that specify\n",
    "    # The different ops for training evaluating, ...\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "                mode=mode, predictions=pred_classes,\n",
    "                loss=loss_op, train_op=train_op,\n",
    "                eval_metric_ops={'accuracy': acc_op})\n",
    "    \n",
    "    return estim_specs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp00nprccw\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp00nprccw', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.Estimator(model_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defne the input function for traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "           x={'images': mnist.train.images}, y=mnist.train.labels,\n",
    "           batch_size=batch_size, num_epochs=None, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp00nprccw/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3260965, step = 1\n",
      "INFO:tensorflow:global_step/sec: 16.5589\n",
      "INFO:tensorflow:loss = 0.12798837, step = 101 (6.040 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5289\n",
      "INFO:tensorflow:loss = 0.13016379, step = 201 (6.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5637\n",
      "INFO:tensorflow:loss = 0.019065345, step = 301 (6.038 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5879\n",
      "INFO:tensorflow:loss = 0.054357566, step = 401 (6.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6857\n",
      "INFO:tensorflow:loss = 0.028769184, step = 501 (5.993 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7556\n",
      "INFO:tensorflow:loss = 0.01605868, step = 601 (5.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7468\n",
      "INFO:tensorflow:loss = 0.017276177, step = 701 (5.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6312\n",
      "INFO:tensorflow:loss = 0.01828395, step = 801 (6.013 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5954\n",
      "INFO:tensorflow:loss = 0.08819996, step = 901 (6.025 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.4793\n",
      "INFO:tensorflow:loss = 0.0933257, step = 1001 (6.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5171\n",
      "INFO:tensorflow:loss = 0.012476482, step = 1101 (6.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5607\n",
      "INFO:tensorflow:loss = 0.024886841, step = 1201 (6.038 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7743\n",
      "INFO:tensorflow:loss = 0.026325492, step = 1301 (5.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7381\n",
      "INFO:tensorflow:loss = 0.042650286, step = 1401 (5.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.7737\n",
      "INFO:tensorflow:loss = 0.027913207, step = 1501 (5.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.4985\n",
      "INFO:tensorflow:loss = 0.012902343, step = 1601 (6.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5459\n",
      "INFO:tensorflow:loss = 0.01635262, step = 1701 (6.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6151\n",
      "INFO:tensorflow:loss = 0.016581144, step = 1801 (6.019 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.447\n",
      "INFO:tensorflow:loss = 0.0026869434, step = 1901 (6.081 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/tmp00nprccw/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.04214401.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7f27fef231d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn,steps=num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "## Define the input fuction for evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-09-13-08:59:32\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp00nprccw/model.ckpt-2000\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-13-08:59:34\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.9875, global_step = 2000, loss = 0.0389026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9875, 'loss': 0.0389026, 'global_step': 2000}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "            x={'images': mnist.test.images}, y=mnist.test.labels,\n",
    "            batch_size=batch_size, shuffle=False)\n",
    "# Use the Estimator 'evaluate' method\n",
    "model.evaluate(input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__new__() got an unexpected keyword argument 'precisions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8d037ed811fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     x={'images': test_images}, shuffle=False)\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Use the model to predict the images class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path)\u001b[0m\n\u001b[1;32m    338\u001b[0m           input_fn, model_fn_lib.ModeKeys.PREDICT)\n\u001b[1;32m    339\u001b[0m       estimator_spec = self._call_model_fn(features, None,\n\u001b[0;32m--> 340\u001b[0;31m                                            model_fn_lib.ModeKeys.PREDICT)\n\u001b[0m\u001b[1;32m    341\u001b[0m       \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m       with training.MonitoredSession(\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode)\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'config'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_fn_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEstimatorSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-fa12f97d7f30>\u001b[0m in \u001b[0;36mmodel_fn\u001b[0;34m(features, labels, mode)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# If prediction mode, early return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEstimatorSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Define loss and optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __new__() got an unexpected keyword argument 'precisions'"
     ]
    }
   ],
   "source": [
    "# Predict single images\n",
    "n_images = 4\n",
    "# Get images from test set\n",
    "test_images = mnist.test.images[:n_images]\n",
    "# Prepare the input data\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': test_images}, shuffle=False)\n",
    "# Use the model to predict the images class\n",
    "preds = list(model.predict(input_fn))\n",
    "\n",
    "# Display\n",
    "for i in range(n_images):\n",
    "    plt.imshow(np.reshape(test_images[i], [28, 28]), cmap='gray')\n",
    "    plt.show()\n",
    "    print(\"Model prediction:\", preds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
